{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多层全连接神经网络实现MNIST手写数字分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "关键词：线性模型Linear、激活函数ReLU、批标准化BatchNormld、数据加载"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 设置超参数（Hyperparameters）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64   #每一次训练的样本数量\n",
    "learning_rate = 1e-2\n",
    "num_epoch = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "# ToTensor变成 0~1   Normalize变成 -1~1\n",
    "data_tf = transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.5], [0.5])])\n",
    "\n",
    "# train属性是区别并对应加载训练集和测试机\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=data_tf)\n",
    "test_dataset  = datasets.MNIST(root='./data', train=False, transform=data_tf)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 三种模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 简单的三层全连接神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class simpleNet(nn.Module):\n",
    "    def __init__(self, in_dim, n_hidden_1, n_hidden_2, out_dim):\n",
    "        super(simpleNet, self).__init__()\n",
    "        self.layer1 = nn.Linear(in_dim, n_hidden_1)\n",
    "        self.layer2 = nn.Linear(n_hidden_1, n_hidden_2)\n",
    "        self.layer3 = nn.Linear(n_hidden_2, out_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 添加激活函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation_Net(nn.Module):\n",
    "    def __init__(self, in_dim, n_hidden_1, n_hidden_2, out_dim):\n",
    "        super(Activation_Net, self).__init__()\n",
    "        # inplace=True是指对输入数据进行原地改变，不使用新的变量，节省内存空间\n",
    "        self.layer1 = nn.Sequential(nn.Linear(in_dim, n_hidden_1), nn.ReLU(inplace=True)) \n",
    "        self.layer2 = nn.Sequential(nn.Linear(n_hidden_1, n_hidden_2), nn.ReLU(inplace=True)) \n",
    "        self.layer3 = nn.Sequential(nn.Linear(n_hidden_2, out_dim)) \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 添加批标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Batch_Net(nn.Module):\n",
    "    def __init__(self, in_dim, n_hidden_1, n_hidden_2, out_dim):\n",
    "        super(Batch_Net, self).__init__()\n",
    "        # BatchNorm1d 中 '1' 是数字1\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(in_dim, n_hidden_1), \n",
    "            nn.BatchNorm1d(n_hidden_1),\n",
    "            nn.ReLU(True)) \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Linear(n_hidden_1, n_hidden_2), \n",
    "            nn.BatchNorm1d(n_hidden_2),\n",
    "            nn.ReLU(inplace=True)) \n",
    "        self.layer3 = nn.Sequential(nn.Linear(n_hidden_2, out_dim))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 训练及测试网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim, Tensor\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 简单的三层全连接神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "         ...,\n",
       "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "         [-1., -1., -1.,  ..., -1., -1., -1.]]),\n",
       " tensor([2, 7, 6, 7, 4, 3, 8, 0, 2, 3, 9, 4, 1, 5, 5, 7, 6, 1, 6, 2, 5, 0, 4, 1,\n",
       "         7, 5, 6, 3, 1, 2, 2, 3, 8, 4, 5, 1, 3, 0, 2, 6, 6, 9, 6, 6, 2, 6, 3, 1,\n",
       "         2, 9, 6, 6, 3, 3, 9, 9, 4, 1, 4, 0, 3, 1, 2, 5]))"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 数据格式\n",
    "for data in train_loader:\n",
    "    img, label = data\n",
    "    img = img.view(img.size(0), -1)\n",
    "    #print('img:\\n',img)\n",
    "    #print('label:\\b',label)\n",
    "    break\n",
    "img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label:\n",
      "tensor([2, 7, 6, 7, 4, 3, 8, 0, 2, 3, 9, 4, 1, 5, 5, 7, 6, 1, 6, 2, 5, 0, 4, 1,\n",
      "        7, 5, 6, 3, 1, 2, 2, 3, 8, 4, 5, 1, 3, 0, 2, 6, 6, 9, 6, 6, 2, 6, 3, 1,\n",
      "        2, 9, 6, 6, 3, 3, 9, 9, 4, 1, 4, 0, 3, 1, 2, 5])\n",
      "real_label:\n",
      "tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "for i in label:\n",
    "    n += 1\n",
    "    temp = torch.zeros(1,10)\n",
    "    temp[0][i.item()] = 1\n",
    "    if n==1:\n",
    "        real_label = temp\n",
    "    else:\n",
    "        real_label = torch.cat((real_label, temp), 0)\n",
    "print('label:\\n{}\\nreal_label:\\n{}'.format(label, real_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = simpleNet(28*28, 300, 100, 10)\n",
    "criterion_1 = nn.CrossEntropyLoss()\n",
    "optimizer_1 = optim.SGD(model_1.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red size=5>Q: 为什么label和out的数据格式不同却能算loss</font>\n",
    "- LOSS参数(input, target), 顺序不能反\n",
    "- 函数内部会自动变化？\n",
    "- 交叉熵到底怎么算的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 100/1000, loss: 1.670849\n",
      "epoch: 200/1000, loss: 0.846519\n",
      "epoch: 300/1000, loss: 0.721024\n",
      "epoch: 400/1000, loss: 0.626457\n",
      "epoch: 500/1000, loss: 0.577877\n",
      "epoch: 600/1000, loss: 0.405546\n",
      "epoch: 700/1000, loss: 0.593416\n",
      "epoch: 800/1000, loss: 0.553243\n",
      "epoch: 900/1000, loss: 0.401298\n"
     ]
    }
   ],
   "source": [
    "model_1.train()\n",
    "num = 1000\n",
    "epoch = 0\n",
    "for data in train_loader:\n",
    "    epoch += 1\n",
    "    # forward\n",
    "    img, label = data\n",
    "    img = img.view(img.size(0), -1)\n",
    "    \n",
    "    img = Variable(img)\n",
    "    '''\n",
    "    ###### label\n",
    "    n = 0\n",
    "    for i in label:\n",
    "        n += 1\n",
    "        temp = torch.zeros(1,10)\n",
    "        temp[0][i.item()] = 1\n",
    "        if n==1:\n",
    "            real_label = temp\n",
    "        else:\n",
    "            real_label = torch.cat((real_label, temp), 0)\n",
    "    ######\n",
    "    '''\n",
    "    label = Variable(label)\n",
    "    out = model_1(img)\n",
    "    loss = criterion_1(out, label)\n",
    "    \n",
    "    #backward\n",
    "    optimizer_1.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer_1.step()\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print('epoch: {}/{}, loss: {:.6f}'.format(epoch, num, loss.item()))\n",
    "    \n",
    "    if epoch==num:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img:\n",
      " tensor([[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "        ...,\n",
      "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "        [-1., -1., -1.,  ..., -1., -1., -1.]])\n",
      "lebel:\n",
      " tensor([7, 3, 9, 0, 2, 3, 5, 5, 5, 8, 8, 8, 5, 5, 0, 2, 6, 2, 7, 0, 4, 3, 8, 2,\n",
      "        4, 0, 9, 1, 2, 5, 1, 0, 7, 5, 3, 4, 1, 8, 2, 0, 5, 0, 5, 8, 6, 3, 4, 8,\n",
      "        5, 3, 2, 8, 8, 3, 5, 6, 1, 0, 4, 6, 1, 2, 3, 3])\n",
      "tensor(2.3333, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "for data in train_loader:\n",
    "    \n",
    "    img, label = data\n",
    "    img = img.view(img.size(0), -1)\n",
    "    \n",
    "    out = model_1(img)\n",
    "    break\n",
    "loss = criterion_1(out, label)\n",
    "print('img:\\n',img)\n",
    "print('lebel:\\n',label)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue> torch.max(out,1)返回张量out每一行最大元素以及它的列数</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc : 0.891100\n"
     ]
    }
   ],
   "source": [
    "model_1.eval()\n",
    "acc = 0\n",
    "for data in test_loader:\n",
    "    img, label = data\n",
    "    img = img.view(img.size(0), -1)\n",
    "    img = Variable(img)\n",
    "    out = model_1(img)\n",
    "    a, pred = max(out, 1)\n",
    "    b = (pred == label).sum()\n",
    "    acc += b.item()\n",
    "#print('out: \\n{}\\na:\\n{}\\npred:\\n{}\\nb:\\n{}/{}'.format(out,a,pred,b,pred.size(0)))\n",
    "print('acc : {:.6f}'.format(acc/len(test_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc : 0.894900\n"
     ]
    }
   ],
   "source": [
    "print('acc : {:.6f}'.format(acc/len(test_dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 添加激活函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>Q:加了激活函数反而准确率下降了 </font>\n",
    "- 认为是label需要再处理成one-hot形式，但是处理之后反而运行错误\n",
    "- <font color=red>A:网络结构错误地在最后一层加了一个激活函数 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = Activation_Net(28*28, 300, 100, 10)\n",
    "criterion_2 = nn.CrossEntropyLoss()\n",
    "optimizer_2 = optim.SGD(model_2.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 100/1000, loss: 2.021912\n",
      "epoch: 200/1000, loss: 1.539746\n",
      "epoch: 300/1000, loss: 1.087095\n",
      "epoch: 400/1000, loss: 0.856249\n",
      "epoch: 500/1000, loss: 0.553302\n",
      "epoch: 600/1000, loss: 0.473291\n",
      "epoch: 700/1000, loss: 0.506441\n",
      "epoch: 800/1000, loss: 0.301461\n",
      "epoch: 900/1000, loss: 0.348901\n"
     ]
    }
   ],
   "source": [
    "model_2.train()\n",
    "num = 1000\n",
    "epoch = 0\n",
    "for data in train_loader:\n",
    "    epoch += 1\n",
    "    # forward\n",
    "    img, label = data\n",
    "    img = img.view(img.size(0), -1)\n",
    "    \n",
    "    img = Variable(img)\n",
    "    label = Variable(label)\n",
    "    \n",
    "    out = model_2(img)\n",
    "    loss = criterion_2(out, label)\n",
    "    \n",
    "    #backward\n",
    "    optimizer_2.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer_2.step()\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print('epoch: {}/{}, loss: {:.6f}'.format(epoch, num, loss.item()))\n",
    "    \n",
    "    if epoch==num:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.887\n"
     ]
    }
   ],
   "source": [
    "model_2.eval()\n",
    "acc = 0\n",
    "for data in test_loader:\n",
    "    img, label = data\n",
    "    img = img.view(img.size(0), -1)\n",
    "    img = Variable(img)\n",
    "    out = model_2(img)\n",
    "    a, pred = max(out, 1)\n",
    "    b = (pred == label).sum()\n",
    "    acc += b.item()\n",
    "print(acc/len(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 添加批标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = Batch_Net(28*28, 300, 100, 10)\n",
    "criterion_3 = nn.CrossEntropyLoss()\n",
    "optimizer_3 = optim.SGD(model_3.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 100/1000, loss: 1.392313\n",
      "epoch: 200/1000, loss: 1.110351\n",
      "epoch: 300/1000, loss: 0.909655\n",
      "epoch: 400/1000, loss: 0.595646\n",
      "epoch: 500/1000, loss: 0.602998\n",
      "epoch: 600/1000, loss: 0.356907\n",
      "epoch: 700/1000, loss: 0.416577\n",
      "epoch: 800/1000, loss: 0.354607\n",
      "epoch: 900/1000, loss: 0.310528\n"
     ]
    }
   ],
   "source": [
    "model_3.train()\n",
    "num = 1000\n",
    "epoch = 0\n",
    "for data in train_loader:\n",
    "    epoch += 1\n",
    "    # forward\n",
    "    img, label = data\n",
    "    img = img.view(img.size(0), -1)\n",
    "    \n",
    "    img = Variable(img)\n",
    "    label = Variable(label)\n",
    "    \n",
    "    out = model_3(img)\n",
    "    loss = criterion_3(out, label)\n",
    "    \n",
    "    #backward\n",
    "    optimizer_3.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer_3.step()\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print('epoch: {}/{}, loss: {:.6f}'.format(epoch, num, loss.item()))\n",
    "    \n",
    "    if epoch==num:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9417\n"
     ]
    }
   ],
   "source": [
    "model_3.eval()\n",
    "acc = 0\n",
    "for data in test_loader:\n",
    "    img, label = data\n",
    "    img = img.view(img.size(0), -1)\n",
    "    img = Variable(img)\n",
    "    out = model_3(img)\n",
    "    a, pred = max(out, 1)\n",
    "    b = (pred == label).sum()\n",
    "    acc += b.item()\n",
    "print(acc/len(test_dataset))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
