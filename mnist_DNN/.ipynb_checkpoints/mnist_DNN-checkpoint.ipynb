{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多层全连接神经网络实现MNIST手写数字分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "关键词：线性模型Linear、激活函数ReLU、批标准化BatchNormld、数据加载"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 设置超参数（Hyperparameters）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64   #每一次训练的样本数量\n",
    "learning_rate = 1e-2\n",
    "num_epoch = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "data_tf = transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.5], [0.5])])\n",
    "\n",
    "# train属性是区别并对应加载训练集和测试机\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=data_tf)\n",
    "test_dataset  = datasets.MNIST(root='./data', train=False, transform=data_tf)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 三种模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 简单的三层全连接神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class simpleNet(nn.Module):\n",
    "    def __init__(self, in_dim, n_hidden_1, n_hidden_2, out_dim):\n",
    "        super(simpleNet, self).__init__()\n",
    "        self.layer1 = nn.Linear(in_dim, n_hidden_1)\n",
    "        self.layer2 = nn.Linear(n_hidden_1, n_hidden_2)\n",
    "        self.layer3 = nn.Linear(n_hidden_2, out_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 添加激活函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation_Net(nn.Module):\n",
    "    def __init__(self, in_dim, n_hidden_1, n_hidden_2, out_dim):\n",
    "        super(Activation_Net, self).__init__()\n",
    "        # inplace=True是指对输入数据进行原地改变，不使用新的变量，节省内存空间\n",
    "        self.layer1 = nn.Sequential(nn.Linear(in_dim, n_hidden_1), nn.ReLU(inplace=True)) \n",
    "        self.layer2 = nn.Sequential(nn.Linear(n_hidden_1, n_hidden_2), nn.ReLU(inplace=True)) \n",
    "        self.layer3 = nn.Sequential(nn.Linear(n_hidden_2, out_dim), nn.ReLU(inplace=True)) \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 添加批标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Batch_Net(nn.Module):\n",
    "    def __init__(self, in_dim, n_hidden_1, n_hidden_2, out_dim):\n",
    "        super(Batch_Net, self).__init__()\n",
    "        # BatchNorm1d 中 '1' 是数字1\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(in_dim, n_hidden_1), \n",
    "            nn.BatchNorm1d(n_hidden_1),\n",
    "            nn.ReLU(True)) \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Linear(n_hidden_1, n_hidden_2), \n",
    "            nn.BatchNorm1d(n_hidden_2),\n",
    "            nn.ReLU(inplace=True)) \n",
    "        self.layer1 = nn.Sequential(nn.Linear(n_hidden_2, out_dim), nn.ReLU(inplace=True)) \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 训练及测试网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim, Tensor\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 简单的三层全连接神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img:\n",
      " tensor([[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "        ...,\n",
      "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "        [-1., -1., -1.,  ..., -1., -1., -1.]])\n",
      "label:\b tensor([0, 1, 6, 7, 0, 0, 3, 8, 4, 4, 5, 2, 9, 5, 8, 9, 6, 8, 7, 3, 8, 8, 0, 1,\n",
      "        7, 8, 8, 5, 2, 6, 7, 2, 3, 5, 0, 4, 8, 1, 8, 9, 5, 1, 3, 1, 1, 4, 8, 7,\n",
      "        8, 0, 0, 0, 1, 1, 2, 9, 4, 6, 1, 8, 8, 5, 5, 9])\n"
     ]
    }
   ],
   "source": [
    "# 数据格式\n",
    "for data in train_loader:\n",
    "    img, label = data\n",
    "    img = img.view(img.size(0), -1)\n",
    "    print('img:\\n',img)\n",
    "    print('label:\\b',label)\n",
    "    break\n",
    "img, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 5, 9, 2, 3, 2, 1, 6, 6, 1, 4, 9, 9, 6, 1, 0, 0, 0, 4, 1, 9, 7, 8, 3,\n",
      "        7, 3, 4, 6, 4, 5, 5, 5, 9, 7, 7, 6, 1, 4, 7, 7, 9, 2, 0, 1, 2, 1, 7, 9,\n",
      "        7, 1, 0, 8, 7, 1, 5, 6, 7, 2, 9, 6, 8, 6, 9, 0])\n",
      "tensor([[-1.2809e+00, -1.2003e-01,  3.5806e-01,  1.6877e+00, -1.9977e+00,\n",
      "          3.4084e+00, -3.4300e-01, -1.5197e+00,  4.6814e-01, -1.2811e+00],\n",
      "        [ 2.5626e+00, -4.6572e+00, -3.5582e+00,  1.0630e+00, -1.8602e+00,\n",
      "          1.1259e+01, -5.1556e+00, -6.6359e+00,  6.7563e+00, -1.9455e+00],\n",
      "        [-3.9840e+00, -6.8104e+00,  1.9541e+00, -7.9383e-01,  2.9716e+00,\n",
      "         -4.4529e+00, -3.6774e+00,  4.4158e+00,  1.7016e+00,  7.8981e+00],\n",
      "        [-1.0204e+00, -2.4762e+00,  9.8694e+00,  4.3000e-01,  1.0583e+00,\n",
      "          8.4748e-02,  3.7658e+00, -8.9821e+00,  2.1102e+00, -5.6647e+00],\n",
      "        [-1.2028e+00, -1.3707e+00,  7.5013e-01,  6.0447e+00, -2.9314e+00,\n",
      "          4.0909e+00,  2.4539e+00, -6.9472e+00,  1.2055e+00, -2.8189e+00],\n",
      "        [-1.7025e+00,  1.8573e+00,  1.2961e+01,  2.8095e+00, -3.9616e+00,\n",
      "         -5.1830e-01,  8.3586e+00, -1.3368e+01,  2.3372e+00, -9.5960e+00],\n",
      "        [-4.1688e+00,  6.5650e+00,  2.9341e+00,  1.4537e+00, -6.0509e+00,\n",
      "          1.2936e+00,  9.3511e-02, -3.0516e+00,  3.2277e+00, -2.7519e+00],\n",
      "        [ 1.0558e-01, -6.1965e+00,  4.3737e+00, -3.8523e+00,  1.7827e+00,\n",
      "          1.3412e+00,  9.1595e+00, -6.8153e+00,  1.0173e+00, -2.8988e+00],\n",
      "        [-7.1035e-01, -4.3380e+00,  1.3734e+00, -4.7777e+00,  3.1678e+00,\n",
      "         -1.1313e-01,  6.2114e+00, -1.3966e+00, -1.2128e+00,  3.8135e-01],\n",
      "        [-6.6019e+00,  8.1671e+00,  1.9474e+00,  1.4547e+00, -4.7175e+00,\n",
      "          3.6407e-01, -7.0387e-01, -7.9432e-01,  2.0299e+00, -1.4666e+00],\n",
      "        [-3.4589e+00, -8.3265e+00, -2.9958e+00, -2.7208e+00,  9.9394e+00,\n",
      "          1.0626e+00,  6.4536e-01, -4.6787e+00,  3.4329e+00,  6.0295e+00],\n",
      "        [-6.0928e+00, -3.7483e+00, -1.3477e+00,  2.0990e+00,  3.5235e+00,\n",
      "          9.8859e-02, -4.1828e+00,  1.4461e+00,  1.8406e+00,  4.7992e+00],\n",
      "        [-1.7103e+00, -9.6588e+00, -2.9152e+00,  8.8980e-02,  2.8367e+00,\n",
      "          4.8352e-01, -4.4888e+00,  1.9461e+00,  3.4613e+00,  7.9768e+00],\n",
      "        [-6.8929e-02, -4.4792e+00,  4.8496e+00, -4.1287e+00,  1.3618e+00,\n",
      "          1.2482e+00,  1.1746e+01, -1.0017e+01,  1.8998e+00, -3.2324e+00],\n",
      "        [-8.1350e+00,  8.4320e+00,  3.8956e+00,  1.3477e+00, -2.4980e+00,\n",
      "         -1.4329e+00, -2.0921e+00, -2.8343e+00,  4.6228e+00, -2.1113e+00],\n",
      "        [ 8.0892e+00, -8.1741e+00,  1.4029e+00,  1.0392e-01, -2.2057e+00,\n",
      "          4.8670e+00, -1.4151e+00, -4.6986e-01, -1.3737e+00, -1.3725e+00],\n",
      "        [ 8.3651e+00, -1.3248e+01,  3.3100e-01,  5.8202e-01,  4.7498e-01,\n",
      "          3.1626e+00,  1.6783e-01, -2.2269e+00,  5.9273e-01,  4.8287e-01],\n",
      "        [ 5.7130e+00, -5.7974e+00,  1.3695e+00,  5.3043e-01, -4.9774e+00,\n",
      "          4.7079e+00, -4.9908e+00,  5.3399e-01,  1.5975e+00,  1.1175e+00],\n",
      "        [-4.2154e+00, -5.3434e+00, -5.0905e+00, -4.5589e+00,  1.1679e+01,\n",
      "          1.1742e+00,  9.0813e-01, -5.9583e-01,  1.0494e+00,  3.4428e+00],\n",
      "        [-5.7112e+00,  8.1145e+00,  3.3074e+00,  1.5008e+00, -4.9722e+00,\n",
      "         -7.9348e-02, -1.3613e+00, -2.0584e+00,  3.1131e+00, -2.1229e+00],\n",
      "        [-3.6261e+00, -5.7858e+00, -4.6640e+00,  1.0718e+00,  5.8021e+00,\n",
      "         -7.2245e-01, -3.6164e+00,  2.0040e+00,  1.0542e+00,  7.4362e+00],\n",
      "        [-8.4299e+00, -2.0397e+00, -3.7127e+00,  1.2438e+00,  3.6664e+00,\n",
      "         -2.1112e+00, -5.1924e+00,  8.4048e+00,  5.1889e-01,  5.7396e+00],\n",
      "        [-4.4786e+00,  1.2142e+00,  2.4991e-01, -3.4674e-01, -2.5683e+00,\n",
      "          1.2936e+00, -3.0714e+00,  5.4823e-01,  4.3392e+00,  1.0213e+00],\n",
      "        [ 3.9561e+00, -3.6622e+00,  2.5265e+00,  4.8834e+00, -5.5513e+00,\n",
      "          3.6685e+00, -1.8893e+00, -2.2765e+00,  9.9934e-01, -2.6848e+00],\n",
      "        [-1.7881e+00, -7.3042e+00, -9.8194e-01, -1.6578e+00,  3.7212e+00,\n",
      "          9.8319e-02, -3.3254e+00,  2.8622e+00,  1.3267e+00,  5.5088e+00],\n",
      "        [-3.6906e+00, -5.1791e-01,  1.8674e+00,  5.0971e+00, -2.2645e+00,\n",
      "          4.4310e+00,  2.9400e-01, -7.7050e+00,  3.8376e+00, -2.9930e+00],\n",
      "        [-5.9290e+00, -5.0503e+00, -4.5708e+00,  1.6460e+00,  7.7288e+00,\n",
      "          6.6697e-01, -3.1910e+00,  1.7040e-01,  9.8187e-01,  6.3412e+00],\n",
      "        [-1.5298e+00, -3.4366e+00,  2.4013e+00, -3.1944e+00,  2.1678e+00,\n",
      "          1.3800e+00,  7.1086e+00, -4.2582e+00, -6.3092e-01, -1.2828e+00],\n",
      "        [-6.2495e+00,  8.7566e-01, -3.5236e+00, -2.3367e+00,  5.3930e+00,\n",
      "          2.8190e+00, -5.9512e-01, -1.4626e+00,  2.3123e+00,  8.7354e-01],\n",
      "        [-1.8968e+00, -1.3222e+00, -3.4060e+00,  6.8411e-01, -9.9046e-01,\n",
      "          4.4825e+00, -2.1642e+00, -6.9375e-01,  1.9699e+00,  1.9566e+00],\n",
      "        [ 1.1090e+00, -6.5388e+00,  6.2890e-01,  1.1248e+00,  1.8118e+00,\n",
      "          6.2755e+00, -1.2263e+00, -7.8430e+00,  4.5785e+00, -1.4699e+00],\n",
      "        [ 2.2779e+00, -8.5947e+00, -6.9250e+00,  5.5127e+00, -1.9047e+00,\n",
      "          5.9991e+00, -1.1954e+01,  6.0911e+00,  2.4500e+00,  5.2053e+00],\n",
      "        [-2.8132e+00, -8.9746e+00, -5.2046e+00, -5.4683e-01,  5.0536e+00,\n",
      "          2.9416e-01, -3.9512e+00,  2.8950e+00,  2.4660e+00,  8.8185e+00],\n",
      "        [-3.1795e+00, -3.0194e+00, -1.6964e+00,  4.1142e-01, -7.1174e-01,\n",
      "         -9.6455e-01, -7.2426e+00,  7.6535e+00,  1.6932e+00,  5.1635e+00],\n",
      "        [-1.5179e+00, -6.2088e+00, -7.3348e+00,  2.3891e+00,  3.6019e+00,\n",
      "          1.4054e+00, -7.0576e+00,  8.1685e+00, -9.6758e-01,  6.4501e+00],\n",
      "        [-4.3650e+00, -8.0815e-01,  2.5799e+00, -1.8606e+00,  1.0923e+00,\n",
      "          1.1973e+00,  5.4757e+00, -5.5628e+00,  2.0109e+00, -1.3133e+00],\n",
      "        [-8.1095e+00,  8.0822e+00,  1.1447e+00,  2.5106e+00, -4.9997e+00,\n",
      "          4.3244e-01, -2.7109e+00, -1.3494e+00,  4.4817e+00, -5.7903e-01],\n",
      "        [-4.0149e+00, -5.8096e+00,  2.0570e-01, -4.2523e+00,  6.1604e+00,\n",
      "         -5.6769e-01,  1.5075e+00,  8.2491e-01,  9.6938e-01,  2.2651e+00],\n",
      "        [-5.5633e+00,  3.2397e+00,  5.4675e-01,  2.2247e+00, -3.0363e+00,\n",
      "         -2.9814e-01, -4.2879e+00,  4.0533e+00,  1.9248e-01,  2.1205e+00],\n",
      "        [ 1.1690e+00, -6.8528e+00, -1.9529e-01, -3.7449e-02, -4.0410e+00,\n",
      "         -1.7985e-01, -9.7387e+00,  1.2471e+01,  7.2963e-01,  4.3850e+00],\n",
      "        [-2.6957e+00, -6.4489e+00, -1.2917e+00, -1.2603e-01,  2.3553e+00,\n",
      "          1.5803e-01, -3.7049e+00,  2.3646e+00,  1.9975e+00,  5.7938e+00],\n",
      "        [ 1.0197e+00, -4.4392e+00,  8.5845e+00, -4.3249e-01, -5.3300e+00,\n",
      "         -1.9453e+00, -1.6240e+00, -1.3008e+00,  4.3658e+00, -2.4518e-01],\n",
      "        [ 8.6148e+00, -7.6413e+00,  2.9982e+00, -3.4078e-01, -3.4201e+00,\n",
      "          5.7847e+00,  1.6915e+00, -4.9591e+00,  2.0663e+00, -5.2044e+00],\n",
      "        [-7.5491e+00,  7.9221e+00,  3.4289e+00,  8.5178e-01, -1.8458e+00,\n",
      "         -1.4794e+00, -2.2126e+00, -1.0248e+00,  3.2075e+00, -1.9963e+00],\n",
      "        [ 8.6794e-01,  1.4124e+00,  9.9332e+00,  2.5630e+00, -4.2634e+00,\n",
      "          1.7786e+00,  5.5555e+00, -1.1940e+01,  1.9729e+00, -8.0850e+00],\n",
      "        [-5.5474e+00,  7.6141e+00,  2.3045e+00,  2.1447e+00, -5.0089e+00,\n",
      "          3.7712e-02, -2.5732e+00,  5.0747e-02,  2.0624e+00, -1.1828e+00],\n",
      "        [-3.2867e+00, -1.8087e+00, -8.5573e-01,  8.7117e-02, -1.7304e+00,\n",
      "         -1.1822e+00, -6.9375e+00,  8.1610e+00,  7.3121e-01,  5.1538e+00],\n",
      "        [-8.4781e+00, -7.6165e-01, -3.9084e+00, -2.6325e+00,  5.6940e+00,\n",
      "         -9.5039e-03,  4.4413e-01, -5.2550e-01,  3.1765e+00,  4.9240e+00],\n",
      "        [-3.3413e+00, -1.7150e+00, -2.4158e-01, -2.7007e+00,  9.6823e-01,\n",
      "         -1.1578e+00, -2.6809e+00,  5.6628e+00,  6.8764e-01,  2.9181e+00],\n",
      "        [-5.7438e+00,  7.4682e+00,  1.9947e+00,  1.8754e+00, -4.7887e+00,\n",
      "          6.0289e-01, -1.5219e+00, -1.1326e+00,  2.6314e+00, -1.5154e+00],\n",
      "        [ 1.6798e+01, -1.6803e+01, -7.9359e-01,  1.7378e+00, -8.7038e+00,\n",
      "          9.8257e+00, -4.1335e+00, -3.3629e+00,  5.8622e+00, -1.6901e+00],\n",
      "        [-2.3448e+00,  2.8843e+00,  5.6931e+00,  3.0469e+00, -5.8004e+00,\n",
      "          2.0202e+00,  2.1513e+00, -8.8650e+00,  5.3453e+00, -4.7624e+00],\n",
      "        [-9.0044e+00,  4.3006e+00,  3.2748e+00,  2.2774e+00, -3.5091e-01,\n",
      "         -2.0586e+00, -7.0732e-01, -1.5495e-01,  1.5347e+00, -3.8943e-01],\n",
      "        [-7.3223e+00,  7.7573e+00,  2.2420e+00,  1.5974e+00, -2.0620e+00,\n",
      "         -1.2235e+00, -3.6183e+00,  1.2661e+00,  1.7931e+00, -1.0946e+00],\n",
      "        [ 2.5097e-01, -1.9963e+00, -1.8117e-01,  6.0199e-01, -3.7184e-02,\n",
      "          5.7635e+00,  2.2253e+00, -5.7930e+00,  9.8674e-01, -2.7371e+00],\n",
      "        [ 1.0774e+00, -7.5561e+00,  7.7394e+00, -6.3130e+00,  3.5779e+00,\n",
      "          3.5007e-01,  1.4577e+01, -1.3091e+01,  2.7539e+00, -4.0774e+00],\n",
      "        [ 1.7040e+00, -8.1459e+00,  4.3638e-01,  3.0696e+00, -5.4019e+00,\n",
      "         -1.5003e+00, -1.0319e+01,  1.3385e+01, -7.3392e-01,  5.8073e+00],\n",
      "        [-2.8513e+00, -2.4895e+00,  1.1104e+01,  2.7907e+00, -2.9809e+00,\n",
      "         -2.9582e+00, -9.3660e-01, -7.0199e+00,  4.8905e+00, -9.1316e-02],\n",
      "        [-4.8244e+00, -1.0501e+00, -4.1144e+00,  1.2643e+00,  2.9322e+00,\n",
      "          9.5924e-01, -5.4568e+00,  4.6472e+00,  7.1097e-01,  3.4106e+00],\n",
      "        [-1.1240e+00, -6.0660e+00,  2.5953e+00, -1.2250e+00,  2.5279e+00,\n",
      "         -2.2738e+00,  4.4758e+00,  1.2340e+00, -1.4392e+00,  8.5365e-02],\n",
      "        [-6.4820e+00,  4.2050e-01,  2.8222e+00,  6.2340e-01, -9.7289e-01,\n",
      "          7.3133e-01,  1.1677e+00, -2.8897e+00,  4.2472e+00, -2.0623e+00],\n",
      "        [ 8.3429e-01, -4.7732e+00,  4.2374e+00, -2.5517e+00, -2.6082e-01,\n",
      "          6.7879e-01,  8.7880e+00, -8.7584e+00,  3.1745e+00, -2.3870e+00],\n",
      "        [ 2.1082e+00, -6.2657e+00,  8.3589e-01, -2.4172e+00,  2.5503e+00,\n",
      "          2.8885e+00,  2.3981e+00, -4.6534e+00,  1.6821e+00, -3.3011e-01],\n",
      "        [ 1.2546e+01, -1.4611e+01,  4.0103e+00,  6.0072e-01, -4.7836e+00,\n",
      "          5.0306e+00, -1.0651e+00, -3.3422e+00,  2.2701e+00, -2.0599e+00]],\n",
      "       grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "for data in train_loader:\n",
    "    img, label = data\n",
    "    break;\n",
    "img = img.view(img.size(0), -1)    \n",
    "img = Variable(img)\n",
    "label = Variable(label)\n",
    "out = model_1(img)\n",
    "print(label)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_1 = criterion_1(out, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = simpleNet(28*28, 300, 100, 10)\n",
    "criterion_1 = nn.CrossEntropyLoss()\n",
    "optimizer_1 = optim.SGD(model_1.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red size=5>Q: 为什么label和out的数据格式不同却能算loss</font>\n",
    "- LOSS参数(input, target), 顺序不能反"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 100/1000, loss: 1.480937\n",
      "epoch: 200/1000, loss: 0.967255\n",
      "epoch: 300/1000, loss: 0.882846\n",
      "epoch: 400/1000, loss: 0.631312\n",
      "epoch: 500/1000, loss: 0.339124\n",
      "epoch: 600/1000, loss: 0.600461\n",
      "epoch: 700/1000, loss: 0.508997\n",
      "epoch: 800/1000, loss: 0.482839\n",
      "epoch: 900/1000, loss: 0.201672\n"
     ]
    }
   ],
   "source": [
    "num = 1000\n",
    "epoch = 0\n",
    "for data in train_loader:\n",
    "    epoch += 1\n",
    "    # forward\n",
    "    img, label = data\n",
    "    img = img.view(img.size(0), -1)\n",
    "    \n",
    "    img = Variable(img)\n",
    "    label = Variable(label)\n",
    "    \n",
    "    out = model_1(img)\n",
    "    loss = criterion_1(out, label)\n",
    "    \n",
    "    #backward\n",
    "    optimizer_1.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer_1.step()\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print('epoch: {}/{}, loss: {:.6f}'.format(epoch, num, loss.item()))\n",
    "    \n",
    "    if epoch==num:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out: \n",
      "tensor([[ 6.2126e-01, -3.1635e+00, -1.8923e+00,  2.0778e+00, -1.0035e+00,\n",
      "         -1.7577e-02, -7.4395e+00,  9.8309e+00, -1.5224e+00,  3.9399e+00],\n",
      "        [ 3.1480e+00, -5.3276e-01,  5.8375e+00,  2.7525e+00, -6.7138e+00,\n",
      "          3.4681e+00,  4.8478e+00, -9.8556e+00,  2.1796e+00, -7.6293e+00],\n",
      "        [-3.8118e+00,  5.0861e+00,  9.0560e-01,  4.4369e-01, -2.0335e+00,\n",
      "          3.3118e-01, -2.9281e-01,  6.5547e-01, -8.2002e-02, -7.8457e-01],\n",
      "        [ 1.0709e+01, -9.2160e+00,  2.9988e-01, -6.8600e-01, -4.7648e+00,\n",
      "          3.5720e+00,  7.0587e-01, -1.2019e+00,  1.2818e-01, -1.2861e+00],\n",
      "        [-9.9028e-01, -4.7108e+00,  1.4316e-01, -2.2846e+00,  4.4996e+00,\n",
      "         -5.6999e-01,  1.9696e-02,  1.4214e+00, -5.3075e-02,  2.7166e+00],\n",
      "        [-4.9137e+00,  5.9972e+00,  7.6212e-01,  1.3125e+00, -2.6012e+00,\n",
      "         -1.8558e-01, -2.1471e+00,  1.6330e+00,  9.4344e-01, -8.4492e-02],\n",
      "        [-3.4119e+00, -3.9334e+00, -4.3798e+00,  1.0747e-01,  5.8935e+00,\n",
      "          3.0832e+00, -1.8226e+00,  1.8068e+00,  1.7938e+00,  3.3571e+00],\n",
      "        [-4.2516e+00, -6.2220e-01, -2.1676e+00,  1.4503e-01,  2.7961e+00,\n",
      "          1.3734e+00, -1.1820e+00,  8.1726e-01,  8.8740e-01,  4.2389e+00],\n",
      "        [ 1.6522e+00, -3.0924e+00,  2.1617e+00, -4.4263e+00,  1.7569e+00,\n",
      "          1.7573e+00,  5.1060e+00, -4.4795e+00,  6.4274e-01, -1.0617e+00],\n",
      "        [-7.8628e-01, -5.0451e+00, -5.1456e+00, -2.6003e+00,  4.4001e+00,\n",
      "          7.5540e-01, -3.3514e+00,  5.4548e+00,  1.4533e+00,  7.2510e+00],\n",
      "        [ 9.0135e+00, -5.7307e+00,  2.3805e+00,  2.1748e+00, -5.2708e+00,\n",
      "          5.9588e+00, -6.3296e-01, -5.0838e+00,  2.3207e+00, -6.1875e+00],\n",
      "        [ 1.0359e+00, -2.0194e+00,  1.8384e+00, -6.3893e-01, -3.5340e-01,\n",
      "          1.3016e+00,  3.1742e+00, -4.3836e+00,  1.7019e+00, -2.9609e+00],\n",
      "        [-1.2307e+00, -5.1692e+00, -3.2509e+00, -1.7879e+00,  4.7176e+00,\n",
      "          4.2523e-01, -2.9793e+00,  3.7759e+00,  7.4529e-01,  6.8045e+00],\n",
      "        [ 9.3185e+00, -8.3453e+00, -7.1698e-01, -9.2759e-01, -2.9559e+00,\n",
      "          4.5612e+00, -2.4232e+00, -1.4489e+00,  2.6332e+00,  6.6695e-01],\n",
      "        [-4.9173e+00,  6.6521e+00,  9.3078e-01,  2.5566e+00, -4.2817e+00,\n",
      "          3.8455e-01, -1.0751e+00,  8.3027e-03,  1.3491e+00, -8.3258e-01],\n",
      "        [ 1.2640e+00, -1.9688e+00, -3.7325e-01,  2.6099e+00, -1.7336e+00,\n",
      "          4.0947e+00, -1.7368e+00, -1.0882e+00,  1.6471e+00, -2.1515e+00],\n",
      "        [-7.3998e-01, -5.3371e+00, -6.2436e-01, -1.3954e+00,  3.3314e+00,\n",
      "         -1.4262e+00, -2.6662e+00,  3.4822e+00,  6.9115e-01,  5.2092e+00],\n",
      "        [ 2.0492e+00, -3.9494e+00, -1.5566e+00,  3.9477e+00, -2.6611e+00,\n",
      "         -5.1694e-02, -7.4803e+00,  9.6628e+00, -2.3779e+00,  2.5955e+00],\n",
      "        [-2.2326e+00, -1.0579e+00,  6.4113e-01,  3.1659e+00, -1.0195e+00,\n",
      "          1.6956e+00,  1.7046e+00, -3.1955e+00,  1.3427e+00, -1.4504e+00],\n",
      "        [-2.5345e+00, -4.2543e+00, -2.5199e+00, -8.1646e-01,  6.3865e+00,\n",
      "          1.2739e+00, -2.7331e-01,  1.0427e+00, -5.4246e-01,  3.9623e+00],\n",
      "        [-1.1292e+00, -4.3286e+00, -6.1207e+00,  1.5068e+00,  2.6724e+00,\n",
      "          2.0454e+00, -7.0179e+00,  6.4799e+00,  1.4878e+00,  6.9848e+00],\n",
      "        [-6.4968e-01, -4.4585e+00,  2.1312e-01, -1.2115e+00,  2.7043e+00,\n",
      "          3.1634e+00,  7.0914e+00, -7.3200e+00,  1.2761e+00, -1.4073e+00],\n",
      "        [-2.5593e+00, -2.9650e-01,  1.4746e+00, -2.4872e+00,  2.5153e+00,\n",
      "         -1.8109e+00,  3.7327e+00, -5.5181e-01, -5.1406e-01, -4.5316e-01],\n",
      "        [ 1.8822e+00, -4.1217e+00, -1.4551e+00,  4.7890e-01,  3.2507e-01,\n",
      "          5.3559e+00,  1.3794e+00, -3.8520e+00,  1.3048e+00, -7.9688e-01],\n",
      "        [-2.7616e+00, -2.4062e+00, -1.2146e+00, -5.1018e-01,  4.3598e+00,\n",
      "          9.1702e-02, -1.0170e+00,  2.5370e+00, -1.3839e+00,  3.2338e+00],\n",
      "        [ 1.4043e+01, -1.1825e+01,  8.0674e-01, -4.7087e+00, -1.9645e+00,\n",
      "          6.5511e+00,  4.7916e+00, -6.1239e+00,  1.7637e+00, -4.6491e+00],\n",
      "        [-7.4719e-02, -2.1589e+00, -2.6138e+00,  1.0546e+00, -2.4687e-02,\n",
      "          1.5168e-01, -5.0932e+00,  7.7092e+00, -1.9576e+00,  4.5640e+00],\n",
      "        [-9.1174e-01, -6.1597e+00, -1.4588e+00, -2.3802e+00,  6.4386e+00,\n",
      "          9.9555e-01,  1.9781e-01, -2.4262e-01,  7.3128e-01,  4.0258e+00],\n",
      "        [ 1.0050e+01, -9.0027e+00,  1.4055e+00,  2.6662e+00, -5.8647e+00,\n",
      "          3.8816e+00, -3.1428e+00, -2.1619e+00,  2.3798e+00, -1.7865e+00],\n",
      "        [-3.7382e+00,  4.4620e+00, -6.8175e-02,  1.1483e+00, -2.0420e+00,\n",
      "          1.7906e+00,  2.0795e-01, -3.1238e-01,  8.9482e-01, -1.2982e+00],\n",
      "        [-1.1113e+00, -1.5305e+00, -2.5658e+00,  7.3632e+00, -3.8000e+00,\n",
      "          3.3141e+00, -4.8092e+00,  2.3136e+00,  4.2755e-01,  7.6736e-01],\n",
      "        [-3.9771e+00,  4.2753e+00, -4.2005e-01,  1.6867e+00, -1.7855e+00,\n",
      "          1.0768e+00, -1.3108e+00,  1.4395e+00,  6.5646e-02,  2.4213e-01],\n",
      "        [-1.3936e+00, -3.0448e+00, -1.4000e+00,  6.8766e+00, -1.1577e+00,\n",
      "          5.2496e+00, -2.6901e+00, -3.3352e+00,  2.3997e+00, -7.0182e-01],\n",
      "        [ 4.7455e+00, -5.4433e+00,  1.2466e+00, -5.7948e+00,  2.5670e+00,\n",
      "          3.1337e+00,  5.8907e+00, -4.1622e+00, -4.9898e-01, -1.7605e+00],\n",
      "        [-1.4876e+00, -1.5309e+00,  1.0168e+00,  1.8456e+00, -1.1154e+00,\n",
      "         -1.5974e+00, -7.3768e+00,  7.1308e+00,  6.7316e-01,  3.6155e+00],\n",
      "        [ 1.8471e+00, -1.6106e+00,  6.8469e+00,  2.0249e+00, -4.0980e+00,\n",
      "          1.3924e+00,  1.5127e+00, -4.1849e+00,  7.9982e-01, -6.6702e+00],\n",
      "        [-5.2563e-02, -3.3697e+00, -5.4323e-01,  2.0729e+00, -7.5543e-01,\n",
      "         -3.1501e-01, -4.7951e+00,  6.8611e+00, -1.5240e+00,  3.5142e+00],\n",
      "        [-4.8476e+00,  6.0615e+00, -2.6413e-01,  1.3590e+00, -2.6910e+00,\n",
      "          1.1468e+00, -1.0679e+00,  9.0143e-01,  1.2542e+00, -2.9836e-01],\n",
      "        [ 1.9022e+00,  1.4916e+00,  4.1502e+00,  4.0379e+00, -7.6081e+00,\n",
      "          2.5045e+00,  6.6668e-01, -4.8261e+00,  1.5203e+00, -5.3658e+00],\n",
      "        [-4.3547e+00,  6.2678e+00,  5.5507e-01,  2.0295e+00, -4.4843e+00,\n",
      "          9.6053e-01, -9.9404e-01, -1.1620e+00,  2.7213e+00, -7.3863e-01],\n",
      "        [-3.1347e+00,  4.8202e+00,  5.0503e-01,  6.8908e-01, -2.2605e+00,\n",
      "          7.9164e-01, -3.4503e-01,  1.0270e+00, -5.3046e-01, -5.3704e-01],\n",
      "        [-1.1735e+00, -2.0629e+00, -1.1319e+00,  8.7894e-01,  8.6503e-04,\n",
      "         -1.0980e-01, -4.7084e+00,  7.0078e+00, -1.3857e+00,  4.5518e+00],\n",
      "        [-6.3083e+00, -1.4402e+00, -2.2076e+00, -5.6866e-01,  6.4992e+00,\n",
      "         -8.4109e-01, -2.6179e+00,  2.7887e+00,  1.8862e+00,  5.0650e+00],\n",
      "        [-2.1463e+00,  2.6828e+00,  3.4393e+00,  4.3852e-01, -1.6746e+00,\n",
      "         -2.6241e-03,  8.6095e-01, -2.9154e+00,  7.4719e-01, -1.9436e+00],\n",
      "        [-2.1697e+00,  2.5404e-02,  4.3605e-01,  4.0095e+00, -2.0873e+00,\n",
      "          2.3441e+00,  4.6071e-01, -1.5842e+00,  9.1148e-02, -1.5787e+00],\n",
      "        [ 1.8855e+00, -4.1499e+00, -1.6890e+00,  3.5888e+00, -1.1615e+00,\n",
      "          5.7144e+00, -8.0144e-01, -4.0373e+00,  2.3340e+00, -1.3221e+00],\n",
      "        [-5.3879e+00,  2.6070e+00,  7.6844e-01,  3.4318e+00, -1.0162e+00,\n",
      "          1.1521e+00, -1.1915e+00, -4.6211e-01,  1.0563e+00,  6.0456e-02],\n",
      "        [-1.7631e+00, -6.3853e-01,  3.5918e+00, -6.0411e-01,  1.1761e+00,\n",
      "         -4.6127e-01,  2.3249e+00, -1.9600e+00, -8.5579e-01, -9.6092e-01],\n",
      "        [-2.9468e+00, -8.5137e+00, -5.2662e+00, -3.0212e-01,  8.7582e+00,\n",
      "          2.2085e+00, -2.7561e+00,  3.7856e-01,  4.0029e+00,  6.8569e+00],\n",
      "        [-1.9496e+00, -5.3457e+00,  3.4417e-01, -2.4726e+00,  6.3568e+00,\n",
      "         -2.1169e+00,  2.4232e-01,  1.5590e+00, -5.8925e-01,  3.6370e+00],\n",
      "        [ 2.2584e+00, -4.3825e+00,  8.6127e-01, -7.2252e-01, -3.3787e-01,\n",
      "          3.2503e+00,  6.6634e+00, -6.2075e+00, -3.9476e-01, -2.7786e+00],\n",
      "        [ 9.6803e-01, -4.1050e+00,  1.5755e-01,  6.1764e+00, -2.6982e+00,\n",
      "          2.8943e+00, -2.4409e+00, -1.4211e+00,  8.8330e-01, -2.0949e-01],\n",
      "        [ 3.1503e+00, -5.1464e+00, -3.7648e+00, -5.5052e-02,  1.8122e+00,\n",
      "          5.5287e+00, -7.4545e-01, -3.5907e-01, -8.9995e-02,  1.2911e+00],\n",
      "        [ 6.5857e-01, -2.5421e+00, -1.6101e+00,  1.9336e+00,  2.2353e-01,\n",
      "          4.1954e+00, -9.8641e-01, -1.1408e+00,  1.1272e+00, -5.9434e-01],\n",
      "        [-1.6017e+00, -7.0764e-01,  3.9872e+00, -1.5214e+00,  9.8401e-01,\n",
      "         -1.3951e+00,  4.4881e+00, -4.0208e+00,  5.3450e-01, -2.6730e+00],\n",
      "        [ 7.0404e+00, -7.9426e+00, -9.9604e-01,  2.9222e-01, -2.8273e+00,\n",
      "          5.1387e+00, -7.8930e-01, -3.7272e+00,  3.9960e+00, -8.1647e-01],\n",
      "        [-5.8493e-01, -7.4454e+00, -8.6473e-01, -2.0347e+00,  7.0883e+00,\n",
      "          1.3176e+00,  1.3188e+00, -1.5339e+00,  1.0459e+00,  2.2653e+00],\n",
      "        [-3.7575e+00,  5.2493e+00,  6.3832e-01,  1.3279e+00, -2.8988e+00,\n",
      "          2.5860e-01, -1.8916e+00,  1.4573e+00,  3.5219e-01,  1.2432e-01],\n",
      "        [-4.6023e-01, -5.7654e+00, -3.6068e+00, -1.9843e+00,  4.7324e+00,\n",
      "         -4.2677e-01, -2.5631e+00,  4.1981e+00,  9.3854e-02,  7.0316e+00],\n",
      "        [ 1.3732e+00, -1.3216e+00, -2.7104e+00, -9.7971e-01,  4.9189e-01,\n",
      "          3.5230e+00, -1.2909e+00,  2.4672e+00, -6.0442e-01,  1.2555e-01],\n",
      "        [-1.3397e+00, -1.9712e+00, -2.3618e+00,  3.6972e+00, -9.0516e-01,\n",
      "         -1.3423e-01, -6.3118e+00,  8.8498e+00, -1.9765e+00,  3.3756e+00],\n",
      "        [ 1.2892e+00, -3.5674e+00,  2.3966e+00, -2.9747e+00, -6.2525e-01,\n",
      "          1.7615e+00,  1.5662e+00, -4.7436e+00,  4.7500e+00,  1.0015e-01],\n",
      "        [-2.2142e+00, -2.0887e+00, -6.4742e-01, -9.7865e-01,  2.6627e+00,\n",
      "          1.3563e+00, -5.4876e-03,  4.1279e-02,  7.7045e-01,  2.5108e+00],\n",
      "        [-2.2358e+00, -8.3985e-01,  3.1352e+00,  3.1012e+00, -8.6199e-01,\n",
      "          4.0797e-01, -9.9966e-01, -3.0417e+00,  1.5024e+00, -2.0820e-01]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "a:\n",
      "tensor([ 9.8309,  5.8375,  5.0861, 10.7086,  4.4996,  5.9972,  5.8935,  4.2389,\n",
      "         5.1060,  7.2510,  9.0135,  3.1742,  6.8045,  9.3185,  6.6521,  4.0947,\n",
      "         5.2092,  9.6628,  3.1659,  6.3865,  6.9848,  7.0914,  3.7327,  5.3559,\n",
      "         4.3598, 14.0430,  7.7092,  6.4386, 10.0503,  4.4620,  7.3632,  4.2753,\n",
      "         6.8766,  5.8907,  7.1308,  6.8469,  6.8611,  6.0615,  4.1502,  6.2678,\n",
      "         4.8202,  7.0078,  6.4992,  3.4393,  4.0095,  5.7144,  3.4318,  3.5918,\n",
      "         8.7582,  6.3568,  6.6634,  6.1764,  5.5287,  4.1954,  4.4881,  7.0404,\n",
      "         7.0883,  5.2493,  7.0316,  3.5230,  8.8498,  4.7500,  2.6627,  3.1352],\n",
      "       grad_fn=<MaxBackward0>)\n",
      "pred:\n",
      "tensor([7, 2, 1, 0, 4, 1, 4, 9, 6, 9, 0, 6, 9, 0, 1, 5, 9, 7, 3, 4, 9, 6, 6, 5,\n",
      "        4, 0, 7, 4, 0, 1, 3, 1, 3, 6, 7, 2, 7, 1, 2, 1, 1, 7, 4, 2, 3, 5, 3, 2,\n",
      "        4, 4, 6, 3, 5, 5, 6, 0, 4, 1, 9, 5, 7, 8, 4, 2])\n",
      "b:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_1.eval()\n",
    "for data in test_loader:\n",
    "    img, label = data\n",
    "    break;\n",
    "img = img.view(img.size(0), -1)\n",
    "img = Variable(img)\n",
    "out = model_1(img)\n",
    "a, pred = max(out, 1)\n",
    "b = (pred == label).sum()\n",
    "print('out: \\n{}\\na:\\n{}\\npred:\\n{}\\nb:\\n'.format(out,a,pred,b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 添加激活函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = Activation_Net(28*28, 300, 100, 10)\n",
    "criterion_2 = nn.CrossEntropyLoss()\n",
    "optimizer_2 = optim.SGD(model_2.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 100/1000, loss: 2.191514\n",
      "epoch: 200/1000, loss: 1.933417\n",
      "epoch: 300/1000, loss: 1.816343\n",
      "epoch: 400/1000, loss: 1.834052\n",
      "epoch: 500/1000, loss: 1.209747\n",
      "epoch: 600/1000, loss: 1.086104\n",
      "epoch: 700/1000, loss: 0.943458\n",
      "epoch: 800/1000, loss: 1.344618\n",
      "epoch: 900/1000, loss: 0.733659\n"
     ]
    }
   ],
   "source": [
    "num = 1000\n",
    "epoch = 0\n",
    "for data in train_loader:\n",
    "    epoch += 1\n",
    "    # forward\n",
    "    img, label = data\n",
    "    img = img.view(img.size(0), -1)\n",
    "    \n",
    "    img = Variable(img)\n",
    "    label = Variable(label)\n",
    "    \n",
    "    out = model_2(img)\n",
    "    loss = criterion_2(out, label)\n",
    "    \n",
    "    #backward\n",
    "    optimizer_2.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer_2.step()\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print('epoch: {}/{}, loss: {:.6f}'.format(epoch, num, loss.item()))\n",
    "    \n",
    "    if epoch==num:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
